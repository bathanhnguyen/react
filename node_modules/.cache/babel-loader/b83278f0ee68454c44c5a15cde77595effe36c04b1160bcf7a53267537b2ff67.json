{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useEffect } from \"react\";\n\n//Code đầu tiên khởi tạo biến speech để lưu trữ đối tượng nhận dạng giọng nói,\n// tùy thuộc vào trình duyệt đang được sử dụng có hỗ trợ webkitSpeechRecognition hay không.\n//  Nếu trình duyệt không hỗ trợ, speech sẽ được gán giá trị null.\nlet speech;\nif (window.webkitSpeechRecognition) {\n  // eslint-disable-next-line\n  const SpeechRecognition = webkitSpeechRecognition;\n  speech = new SpeechRecognition();\n  speech.continuous = true;\n} else {\n  speech = null;\n}\nconst useVoice = () => {\n  _s();\n  const [text, setText] = useState(\"\");\n  const [isListening, setIsListening] = useState(false);\n\n  //Hàm listen được sử dụng để bắt đầu hoặc dừng việc nhận dạng giọng nói.\n  // Nếu isListening đã là true, hàm sẽ dừng việc nhận dạng bằng cách gọi phương thức stop() trên đối tượng speech.\n  // Ngược lại, nếu isListening chưa là true, hàm sẽ bắt đầu nhận dạng bằng cách gọi phương thức start() trên đối tượng speech.\n  const listen = () => {\n    setIsListening(!isListening);\n    if (isListening) {\n      speech.stop();\n    } else {\n      speech.start();\n    }\n  };\n\n  // sử dụng Hook useEffect để đăng ký sự kiện onresult cho đối tượng speech, sẽ được gọi khi nhận dạng giọng nói thành công.\n  // Khi sự kiện này được kích hoạt, văn bản được nhận dạng được lưu trữ vào biến text và cờ isListening được đặt về false.\n\n  useEffect(() => {\n    if (!speech) {\n      return;\n    }\n    speech.onresult = event => {\n      setText(event.results[event.results.length - 1][0].transcript);\n      setIsListening(false);\n      speech.stop();\n    };\n  }, []);\n  return {\n    text,\n    isListening,\n    listen,\n    voiceSupported: speech !== null\n  };\n};\n_s(useVoice, \"YOMFEUt+oC72LKIeNX1WCieAo1w=\");\nexport { useVoice };","map":{"version":3,"names":["useState","useEffect","speech","window","webkitSpeechRecognition","SpeechRecognition","continuous","useVoice","_s","text","setText","isListening","setIsListening","listen","stop","start","onresult","event","results","length","transcript","voiceSupported"],"sources":["C:/Users/win10/Desktop/Khoaluantotnghiep/KLTN-react/src/components/Header/useVoice.js"],"sourcesContent":["import { useState, useEffect } from \"react\";\r\n\r\n//Code đầu tiên khởi tạo biến speech để lưu trữ đối tượng nhận dạng giọng nói,\r\n// tùy thuộc vào trình duyệt đang được sử dụng có hỗ trợ webkitSpeechRecognition hay không.\r\n//  Nếu trình duyệt không hỗ trợ, speech sẽ được gán giá trị null.\r\nlet speech;\r\nif (window.webkitSpeechRecognition) {\r\n    // eslint-disable-next-line\r\n    const SpeechRecognition = webkitSpeechRecognition;\r\n    speech = new SpeechRecognition();\r\n    speech.continuous = true;\r\n} else {\r\n    speech = null;\r\n}\r\n\r\nconst useVoice = () => {\r\n    const [text, setText] = useState(\"\");\r\n    const [isListening, setIsListening] = useState(false);\r\n\r\n    //Hàm listen được sử dụng để bắt đầu hoặc dừng việc nhận dạng giọng nói.\r\n    // Nếu isListening đã là true, hàm sẽ dừng việc nhận dạng bằng cách gọi phương thức stop() trên đối tượng speech.\r\n    // Ngược lại, nếu isListening chưa là true, hàm sẽ bắt đầu nhận dạng bằng cách gọi phương thức start() trên đối tượng speech.\r\n    const listen = () => {\r\n        setIsListening(!isListening);\r\n        if (isListening) {\r\n            speech.stop();\r\n        } else {\r\n            speech.start();\r\n        }\r\n    };\r\n\r\n    // sử dụng Hook useEffect để đăng ký sự kiện onresult cho đối tượng speech, sẽ được gọi khi nhận dạng giọng nói thành công.\r\n    // Khi sự kiện này được kích hoạt, văn bản được nhận dạng được lưu trữ vào biến text và cờ isListening được đặt về false.\r\n\r\n    useEffect(() => {\r\n        if (!speech) {\r\n            return;\r\n        }\r\n        speech.onresult = (event) => {\r\n            setText(event.results[event.results.length - 1][0].transcript);\r\n            setIsListening(false);\r\n            speech.stop();\r\n        };\r\n    }, []);\r\n\r\n    return {\r\n        text,\r\n        isListening,\r\n        listen,\r\n        voiceSupported: speech !== null\r\n    };\r\n};\r\n\r\nexport { useVoice };\r\n\r\n\r\n"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,SAAS,QAAQ,OAAO;;AAE3C;AACA;AACA;AACA,IAAIC,MAAM;AACV,IAAIC,MAAM,CAACC,uBAAuB,EAAE;EAChC;EACA,MAAMC,iBAAiB,GAAGD,uBAAuB;EACjDF,MAAM,GAAG,IAAIG,iBAAiB,CAAC,CAAC;EAChCH,MAAM,CAACI,UAAU,GAAG,IAAI;AAC5B,CAAC,MAAM;EACHJ,MAAM,GAAG,IAAI;AACjB;AAEA,MAAMK,QAAQ,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACnB,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACW,WAAW,EAAEC,cAAc,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;;EAErD;EACA;EACA;EACA,MAAMa,MAAM,GAAGA,CAAA,KAAM;IACjBD,cAAc,CAAC,CAACD,WAAW,CAAC;IAC5B,IAAIA,WAAW,EAAE;MACbT,MAAM,CAACY,IAAI,CAAC,CAAC;IACjB,CAAC,MAAM;MACHZ,MAAM,CAACa,KAAK,CAAC,CAAC;IAClB;EACJ,CAAC;;EAED;EACA;;EAEAd,SAAS,CAAC,MAAM;IACZ,IAAI,CAACC,MAAM,EAAE;MACT;IACJ;IACAA,MAAM,CAACc,QAAQ,GAAIC,KAAK,IAAK;MACzBP,OAAO,CAACO,KAAK,CAACC,OAAO,CAACD,KAAK,CAACC,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACC,UAAU,CAAC;MAC9DR,cAAc,CAAC,KAAK,CAAC;MACrBV,MAAM,CAACY,IAAI,CAAC,CAAC;IACjB,CAAC;EACL,CAAC,EAAE,EAAE,CAAC;EAEN,OAAO;IACHL,IAAI;IACJE,WAAW;IACXE,MAAM;IACNQ,cAAc,EAAEnB,MAAM,KAAK;EAC/B,CAAC;AACL,CAAC;AAACM,EAAA,CApCID,QAAQ;AAsCd,SAASA,QAAQ"},"metadata":{},"sourceType":"module","externalDependencies":[]}